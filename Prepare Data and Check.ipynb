{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c7aa9b2",
   "metadata": {},
   "source": [
    "# Prepare the data, EDA, upsert, and perform check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16444d45",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d66d0b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "from langchain.chains import LLMChain, RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import StuffDocumentsChain\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.globals import set_verbose, set_debug\n",
    "set_debug(True)\n",
    "set_verbose(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b2a3b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420f126a",
   "metadata": {},
   "source": [
    "### Pinecone setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dad92c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(\n",
    "    api_key=os.environ.get(\"PINECONE_API_KEY\")\n",
    ")\n",
    "\n",
    "index_name = \"mekari-test\"\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=768,\n",
    "        metric=\"euclidean\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws', \n",
    "            region='us-east-1'\n",
    "        ) \n",
    "    ) \n",
    "    \n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424ff0a2",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aa1ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"SPOTIFY_REVIEWS.csv\")\n",
    "df=df.drop(\"Unnamed: 0\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dfbb8a",
   "metadata": {},
   "source": [
    "### simple EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4ee4dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   3,377,423\n",
      "mean           67\n",
      "std            93\n",
      "min             1\n",
      "25%            11\n",
      "50%            30\n",
      "75%            81\n",
      "99%           476\n",
      "max         3,753\n",
      "Name: review_text, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.float_format', '{:,.0f}'.format):\n",
    "    print(df['review_text'].astype(str).apply(len).describe(percentiles=[.25, .5, .75, .99]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f33a048",
   "metadata": {},
   "source": [
    "### Exception Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7261a58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integers: 0, Strings: 9965, Floats: 35\n"
     ]
    }
   ],
   "source": [
    "#check review data type (suspicious having floats or integer instead string)\n",
    "def count_types(lst):\n",
    "    int_count = 0\n",
    "    str_count = 0\n",
    "    float_count = 0\n",
    "\n",
    "    for element in lst:\n",
    "        if isinstance(element, int):\n",
    "            int_count += 1\n",
    "        elif isinstance(element, str):\n",
    "            str_count += 1\n",
    "        elif isinstance(element, float):\n",
    "            float_count += 1\n",
    "\n",
    "    return int_count, str_count, float_count\n",
    "int_count, str_count, float_count = count_types(df['review_text'].to_list())\n",
    "\n",
    "print(f\"Integers: {int_count}, Strings: {str_count}, Floats: {float_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43d153ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since 99% of review below 500 character, we limit review to be 500 character\n",
    "max_length = 500\n",
    "\n",
    "#Make sure all data is also string type\n",
    "df['cut'] = df['review_text'].astype(str).apply(lambda text: text[:max_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "241dd9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for example we only take 10000 first review\n",
    "df=df.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "327c7b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\predator\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "#embed using hugging face\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "df['embeddings']=df.apply(lambda row: embeddings.embed_query(row['cut']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3750eaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save embed data\n",
    "df=pd.read_csv('embed_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2427f5c6",
   "metadata": {},
   "source": [
    "### Upsert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fc44169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data for upsert\n",
    "embeddings_list = df['embeddings'].apply(ast.literal_eval).tolist()\n",
    "df['cut'] = df['cut'].astype(str)\n",
    "documents = df['cut'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a9e391f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserted batch 1\n",
      "Upserted batch 2\n",
      "Upserted batch 3\n",
      "Upserted batch 4\n",
      "Upserted batch 5\n",
      "Upserted batch 6\n",
      "Upserted batch 7\n",
      "Upserted batch 8\n",
      "Upserted batch 9\n",
      "Upserted batch 10\n",
      "Upserted batch 11\n",
      "Upserted batch 12\n",
      "Upserted batch 13\n",
      "Upserted batch 14\n",
      "Upserted batch 15\n",
      "Upserted batch 16\n",
      "Upserted batch 17\n",
      "Upserted batch 18\n",
      "Upserted batch 19\n",
      "Upserted batch 20\n",
      "Upserted batch 21\n",
      "Upserted batch 22\n",
      "Upserted batch 23\n",
      "Upserted batch 24\n",
      "Upserted batch 25\n",
      "Upserted batch 26\n",
      "Upserted batch 27\n",
      "Upserted batch 28\n",
      "Upserted batch 29\n",
      "Upserted batch 30\n",
      "Upserted batch 31\n",
      "Upserted batch 32\n",
      "Upserted batch 33\n",
      "Upserted batch 34\n",
      "Upserted batch 35\n",
      "Upserted batch 36\n",
      "Upserted batch 37\n",
      "Upserted batch 38\n",
      "Upserted batch 39\n",
      "Upserted batch 40\n",
      "Upserted batch 41\n",
      "Upserted batch 42\n",
      "Upserted batch 43\n",
      "Upserted batch 44\n",
      "Upserted batch 45\n",
      "Upserted batch 46\n",
      "Upserted batch 47\n",
      "Upserted batch 48\n",
      "Upserted batch 49\n",
      "Upserted batch 50\n",
      "Upserted batch 51\n",
      "Upserted batch 52\n",
      "Upserted batch 53\n",
      "Upserted batch 54\n",
      "Upserted batch 55\n",
      "Upserted batch 56\n",
      "Upserted batch 57\n",
      "Upserted batch 58\n",
      "Upserted batch 59\n",
      "Upserted batch 60\n",
      "Upserted batch 61\n",
      "Upserted batch 62\n",
      "Upserted batch 63\n",
      "Upserted batch 64\n",
      "Upserted batch 65\n",
      "Upserted batch 66\n",
      "Upserted batch 67\n",
      "Upserted batch 68\n",
      "Upserted batch 69\n",
      "Upserted batch 70\n",
      "Upserted batch 71\n",
      "Upserted batch 72\n",
      "Upserted batch 73\n",
      "Upserted batch 74\n",
      "Upserted batch 75\n",
      "Upserted batch 76\n",
      "Upserted batch 77\n",
      "Upserted batch 78\n",
      "Upserted batch 79\n",
      "Upserted batch 80\n",
      "Upserted batch 81\n",
      "Upserted batch 82\n",
      "Upserted batch 83\n",
      "Upserted batch 84\n",
      "Upserted batch 85\n",
      "Upserted batch 86\n",
      "Upserted batch 87\n",
      "Upserted batch 88\n",
      "Upserted batch 89\n",
      "Upserted batch 90\n",
      "Upserted batch 91\n",
      "Upserted batch 92\n",
      "Upserted batch 93\n",
      "Upserted batch 94\n",
      "Upserted batch 95\n",
      "Upserted batch 96\n",
      "Upserted batch 97\n",
      "Upserted batch 98\n",
      "Upserted batch 99\n",
      "Upserted batch 100\n",
      "All data upserted.\n"
     ]
    }
   ],
   "source": [
    "# Prepare upsert batch\n",
    "upsert_data = [(str(i), embeddings, {\"text\": doc}) for i, (embeddings, doc) in enumerate(zip(embeddings_list, documents))]\n",
    "\n",
    "# Upsert data in batches\n",
    "batch_size = 100\n",
    "for i in range(0, len(upsert_data), batch_size):\n",
    "    batch = upsert_data[i:i + batch_size]\n",
    "    index.upsert(vectors=batch)\n",
    "    print(f\"Upserted batch {i // batch_size + 1}\")\n",
    "\n",
    "print(\"All data upserted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b242f9d1",
   "metadata": {},
   "source": [
    "### Perform check on upsert, vector store, llm, and chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bdc2553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 768,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 10000}},\n",
      " 'total_vector_count': 10000}\n"
     ]
    }
   ],
   "source": [
    "#check if vector sucessfully upsert\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1ebb810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity search results:\n",
      "ID: id-8397, Score: 0.742148876\n",
      "ID: id-9351, Score: 0.769828677\n",
      "ID: id-1217, Score: 0.849857092\n"
     ]
    }
   ],
   "source": [
    "#Check using similairty search\n",
    "#Generate embedding for the query text\n",
    "query_text = \"good features\"\n",
    "query_embedding = embeddings.embed_query(query_text)\n",
    "\n",
    "#Perform a similarity search\n",
    "response = index.query(\n",
    "    namespace=\"\",\n",
    "    vector=query_embedding,\n",
    "    top_k=3,\n",
    "    include_values=True\n",
    ")\n",
    "\n",
    "#Print the results\n",
    "print(\"Similarity search results:\")\n",
    "for match in response['matches']:\n",
    "    print(f\"ID: {match['id']}, Score: {match['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7cd50b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check LLM and key\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    google_api_key=os.environ.get(\"GOOGLE_API_KEY\"),\n",
    "    convert_system_message_to_human=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61839889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**LLM stands for Large Language Model.**\\n\\n**What is a Large Language Model (LLM)?**\\n\\nA large language model is a type of artificial intelligence (AI) system that is trained on a massive dataset of text and code. LLMs are capable of understanding and generating human-like text in response to a wide range of prompts and questions.\\n\\n**Key Characteristics of LLMs:**\\n\\n* **Massive Size:** LLMs typically have billions or even trillions of parameters, making them significantly larger than traditional language models.\\n* **Deep Learning:** They are trained using deep learning algorithms, specifically transformer networks, which allow them to capture complex patterns in language.\\n* **Text Generation:** LLMs excel at generating coherent and grammatically correct text, including articles, stories, summaries, and conversations.\\n* **Language Understanding:** They can understand the meaning and context of text, enabling them to perform tasks like question answering, sentiment analysis, and translation.\\n* **Code Generation:** Some LLMs are also capable of generating computer code in various programming languages.\\n\\n**How LLMs Work:**\\n\\nLLMs are trained on vast amounts of text data using unsupervised learning. During training, they learn to predict the next word in a sequence based on the preceding words. This process allows them to develop a deep understanding of language structure, grammar, and semantics.\\n\\n**Examples of LLMs:**\\n\\n* **GPT-3 (Generative Pre-trained Transformer 3)** by OpenAI\\n* **LaMDA (Language Model for Dialogue Applications)** by Google\\n* **BERT (Bidirectional Encoder Representations from Transformers)** by Google\\n* **PaLM (Pathway Language Model)** by Google\\n\\n**Applications of LLMs:**\\n\\n* **Chatbots and Conversational AI**\\n* **Content Creation (articles, stories, poems)**\\n* **Machine Translation**\\n* **Code Completion and Generation**\\n* **Sentiment Analysis and Social Media Monitoring**\\n* **Question Answering Systems**\\n* **Summarization and Information Extraction**\\n\\n**Benefits of LLMs:**\\n\\n* **Enhanced Language Capabilities:** LLMs offer significant improvements in text generation, understanding, and translation.\\n* **Automation Potential:** They can automate various language-based tasks, freeing up human resources.\\n* **Personalization:** LLMs can be fine-tuned to specific domains or user preferences.\\n\\n**Limitations of LLMs:**\\n\\n* **Bias and Fairness:** LLMs can inherit biases present in their training data.\\n* **Lack of Common Sense:** They may struggle with tasks that require real-world knowledge or common sense.\\n* **Ethical Concerns:** There are concerns about the potential misuse of LLMs, such as generating fake news or impersonating individuals.\\n', response_metadata={'finish_reason': 'STOP', 'safety_ratings': [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}]}, id='run-148c7773-eec5-4ff2-a6a7-0b2f935be0b7-0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"what is llm?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f8681225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if vector stored in pinecone\n",
    "vectorstore = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca8f0f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt_template = \"\"\"\n",
    "Thees are Document of Google Store reviews for a music streaming application (Spotify) sourced from various users. The management is currently\n",
    "facing difficulties in extracting actionable insights from these reviews, Please answer this Question.\n",
    "\n",
    "Document: {document}\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ca28dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"document\", \"question\"],\n",
    "    template=custom_prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df5c1874",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=custom_prompt)\n",
    "combine_documents_chain = StuffDocumentsChain(llm_chain=llm_chain,document_variable_name=\"document\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2c67adfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA(\n",
    "    retriever=retriever,\n",
    "    combine_documents_chain=combine_documents_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f17cbd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"\"\"\"What are the specific features or aspects that users appreciate the\n",
    "most in our application?\"\"\"\n",
    "query2 = \"\"\"In comparison to our application, which music streaming platform are\n",
    "users most likely to compare ours with\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e12e1a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1\n",
      "\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"\\\"What are the specific features or aspects that users appreciate the\\nmost in our application?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"\\\"What are the specific features or aspects that users appreciate the\\nmost in our application?\",\n",
      "  \"document\": \"Everything I could ever want in an app.\\n\\nStreaming, personal list, and media ... quality ... best of all worlds\\n\\nGood app. Thats all\\n\\nToo many new features not requested by the user's.  Only poor app developers do that.  Listen to us, it will save you money researching, implementing then removing what we don't want.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:ChatGoogleGenerativeAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: \\nThees are Document of Google Store reviews for a music streaming application (Spotify) sourced from various users. The management is currently\\nfacing difficulties in extracting actionable insights from these reviews, Please answer this Question.\\n\\nDocument: Everything I could ever want in an app.\\n\\nStreaming, personal list, and media ... quality ... best of all worlds\\n\\nGood app. Thats all\\n\\nToo many new features not requested by the user's.  Only poor app developers do that.  Listen to us, it will save you money researching, implementing then removing what we don't want.\\nQuestion: \\\"What are the specific features or aspects that users appreciate the\\nmost in our application?\\nAnswer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:ChatGoogleGenerativeAI] [6.07s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Based on the provided reviews, here's what users seem to appreciate about the music streaming application:\\n\\n* **Core Functionality:** Users value the fundamental aspects of a music app.  The review mentioning \\\"Streaming, personal list, and media...quality...best of all worlds\\\" highlights the importance of:\\n    * **Seamless Streaming:**  A smooth, uninterrupted listening experience.\\n    * **Personalized Playlists:** The ability to create and manage custom playlists.\\n    * **High-Quality Media:** Access to music tracks with good sound quality.\\n\\n* **Simplicity and Effectiveness:** The short review \\\"Good app. That's all\\\" suggests that some users appreciate the app for being straightforward and effective in its primary function. \\n\\n**Important Note:** While these reviews provide some positive insights, it's crucial to consider the negative feedback as well. The review criticizing the addition of unwanted features highlights a potential area for improvement. Listening to user feedback about unnecessary features and prioritizing core functionality is essential for user satisfaction. \\n\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": 9,\n",
      "              \"probability\": 1,\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": 8,\n",
      "              \"probability\": 1,\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": 7,\n",
      "              \"probability\": 1,\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": 10,\n",
      "              \"probability\": 1,\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Based on the provided reviews, here's what users seem to appreciate about the music streaming application:\\n\\n* **Core Functionality:** Users value the fundamental aspects of a music app.  The review mentioning \\\"Streaming, personal list, and media...quality...best of all worlds\\\" highlights the importance of:\\n    * **Seamless Streaming:**  A smooth, uninterrupted listening experience.\\n    * **Personalized Playlists:** The ability to create and manage custom playlists.\\n    * **High-Quality Media:** Access to music tracks with good sound quality.\\n\\n* **Simplicity and Effectiveness:** The short review \\\"Good app. That's all\\\" suggests that some users appreciate the app for being straightforward and effective in its primary function. \\n\\n**Important Note:** While these reviews provide some positive insights, it's crucial to consider the negative feedback as well. The review criticizing the addition of unwanted features highlights a potential area for improvement. Listening to user feedback about unnecessary features and prioritizing core functionality is essential for user satisfaction. \\n\",\n",
      "            \"response_metadata\": {\n",
      "              \"finish_reason\": \"STOP\",\n",
      "              \"safety_ratings\": [\n",
      "                {\n",
      "                  \"category\": 9,\n",
      "                  \"probability\": 1,\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": 8,\n",
      "                  \"probability\": 1,\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": 7,\n",
      "                  \"probability\": 1,\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": 10,\n",
      "                  \"probability\": 1,\n",
      "                  \"blocked\": false\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-60e5b432-34f7-4dd6-abe5-f0d7e1730096-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {},\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] [6.07s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Based on the provided reviews, here's what users seem to appreciate about the music streaming application:\\n\\n* **Core Functionality:** Users value the fundamental aspects of a music app.  The review mentioning \\\"Streaming, personal list, and media...quality...best of all worlds\\\" highlights the importance of:\\n    * **Seamless Streaming:**  A smooth, uninterrupted listening experience.\\n    * **Personalized Playlists:** The ability to create and manage custom playlists.\\n    * **High-Quality Media:** Access to music tracks with good sound quality.\\n\\n* **Simplicity and Effectiveness:** The short review \\\"Good app. That's all\\\" suggests that some users appreciate the app for being straightforward and effective in its primary function. \\n\\n**Important Note:** While these reviews provide some positive insights, it's crucial to consider the negative feedback as well. The review criticizing the addition of unwanted features highlights a potential area for improvement. Listening to user feedback about unnecessary features and prioritizing core functionality is essential for user satisfaction. \\n\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] [6.07s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"Based on the provided reviews, here's what users seem to appreciate about the music streaming application:\\n\\n* **Core Functionality:** Users value the fundamental aspects of a music app.  The review mentioning \\\"Streaming, personal list, and media...quality...best of all worlds\\\" highlights the importance of:\\n    * **Seamless Streaming:**  A smooth, uninterrupted listening experience.\\n    * **Personalized Playlists:** The ability to create and manage custom playlists.\\n    * **High-Quality Media:** Access to music tracks with good sound quality.\\n\\n* **Simplicity and Effectiveness:** The short review \\\"Good app. That's all\\\" suggests that some users appreciate the app for being straightforward and effective in its primary function. \\n\\n**Important Note:** While these reviews provide some positive insights, it's crucial to consider the negative feedback as well. The review criticizing the addition of unwanted features highlights a potential area for improvement. Listening to user feedback about unnecessary features and prioritizing core functionality is essential for user satisfaction. \\n\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA] [8.00s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"result\": \"Based on the provided reviews, here's what users seem to appreciate about the music streaming application:\\n\\n* **Core Functionality:** Users value the fundamental aspects of a music app.  The review mentioning \\\"Streaming, personal list, and media...quality...best of all worlds\\\" highlights the importance of:\\n    * **Seamless Streaming:**  A smooth, uninterrupted listening experience.\\n    * **Personalized Playlists:** The ability to create and manage custom playlists.\\n    * **High-Quality Media:** Access to music tracks with good sound quality.\\n\\n* **Simplicity and Effectiveness:** The short review \\\"Good app. That's all\\\" suggests that some users appreciate the app for being straightforward and effective in its primary function. \\n\\n**Important Note:** While these reviews provide some positive insights, it's crucial to consider the negative feedback as well. The review criticizing the addition of unwanted features highlights a potential area for improvement. Listening to user feedback about unnecessary features and prioritizing core functionality is essential for user satisfaction. \\n\"\n",
      "}\n",
      "Based on the provided reviews, here's what users seem to appreciate about the music streaming application:\n",
      "\n",
      "* **Core Functionality:** Users value the fundamental aspects of a music app.  The review mentioning \"Streaming, personal list, and media...quality...best of all worlds\" highlights the importance of:\n",
      "    * **Seamless Streaming:**  A smooth, uninterrupted listening experience.\n",
      "    * **Personalized Playlists:** The ability to create and manage custom playlists.\n",
      "    * **High-Quality Media:** Access to music tracks with good sound quality.\n",
      "\n",
      "* **Simplicity and Effectiveness:** The short review \"Good app. That's all\" suggests that some users appreciate the app for being straightforward and effective in its primary function. \n",
      "\n",
      "**Important Note:** While these reviews provide some positive insights, it's crucial to consider the negative feedback as well. The review criticizing the addition of unwanted features highlights a potential area for improvement. Listening to user feedback about unnecessary features and prioritizing core functionality is essential for user satisfaction. \n",
      "\n",
      "\n",
      "Query 2\n",
      "\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"In comparison to our application, which music streaming platform are\\nusers most likely to compare ours with\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"In comparison to our application, which music streaming platform are\\nusers most likely to compare ours with\",\n",
      "  \"document\": \"Best Music Streaming Service\\n\\nNo better music service\\n\\nExactly what I've been looking for in a music streaming app\\n\\nThis is by far the best music app and its hard to say but its better than pandora\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:ChatGoogleGenerativeAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: \\nThees are Document of Google Store reviews for a music streaming application (Spotify) sourced from various users. The management is currently\\nfacing difficulties in extracting actionable insights from these reviews, Please answer this Question.\\n\\nDocument: Best Music Streaming Service\\n\\nNo better music service\\n\\nExactly what I've been looking for in a music streaming app\\n\\nThis is by far the best music app and its hard to say but its better than pandora\\nQuestion: In comparison to our application, which music streaming platform are\\nusers most likely to compare ours with\\nAnswer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:ChatGoogleGenerativeAI] [1.77s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"**Answer:** Pandora \\n\\n**Explanation:**\\n\\nThe user explicitly states, \\\"its better than pandora,\\\" indicating a direct comparison between Spotify and Pandora. This suggests that users perceive these two music streaming services as similar enough to warrant a comparison. \\n\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": 9,\n",
      "              \"probability\": 1,\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": 8,\n",
      "              \"probability\": 1,\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": 7,\n",
      "              \"probability\": 1,\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": 10,\n",
      "              \"probability\": 1,\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"**Answer:** Pandora \\n\\n**Explanation:**\\n\\nThe user explicitly states, \\\"its better than pandora,\\\" indicating a direct comparison between Spotify and Pandora. This suggests that users perceive these two music streaming services as similar enough to warrant a comparison. \\n\",\n",
      "            \"response_metadata\": {\n",
      "              \"finish_reason\": \"STOP\",\n",
      "              \"safety_ratings\": [\n",
      "                {\n",
      "                  \"category\": 9,\n",
      "                  \"probability\": 1,\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": 8,\n",
      "                  \"probability\": 1,\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": 7,\n",
      "                  \"probability\": 1,\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": 10,\n",
      "                  \"probability\": 1,\n",
      "                  \"blocked\": false\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-c75ecf6e-5c44-4a48-b13e-ccdd2642ff75-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {},\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] [1.77s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"**Answer:** Pandora \\n\\n**Explanation:**\\n\\nThe user explicitly states, \\\"its better than pandora,\\\" indicating a direct comparison between Spotify and Pandora. This suggests that users perceive these two music streaming services as similar enough to warrant a comparison. \\n\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] [1.78s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"**Answer:** Pandora \\n\\n**Explanation:**\\n\\nThe user explicitly states, \\\"its better than pandora,\\\" indicating a direct comparison between Spotify and Pandora. This suggests that users perceive these two music streaming services as similar enough to warrant a comparison. \\n\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA] [2.22s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"result\": \"**Answer:** Pandora \\n\\n**Explanation:**\\n\\nThe user explicitly states, \\\"its better than pandora,\\\" indicating a direct comparison between Spotify and Pandora. This suggests that users perceive these two music streaming services as similar enough to warrant a comparison. \\n\"\n",
      "}\n",
      "**Answer:** Pandora \n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "The user explicitly states, \"its better than pandora,\" indicating a direct comparison between Spotify and Pandora. This suggests that users perceive these two music streaming services as similar enough to warrant a comparison. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_query_and_answer(query):\n",
    "    result = qa_chain.invoke(query).get(\"result\")\n",
    "    print(result)\n",
    "\n",
    "print(\"Query 1\\n\")\n",
    "print_query_and_answer(query1)\n",
    "\n",
    "print(\"\\nQuery 2\\n\")\n",
    "print_query_and_answer(query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523f27b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
